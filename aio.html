<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Fundamentals of Classification in Machine Learning: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png">
<link rel="manifest" href="favicons/incubator/site.webmanifest">
<link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="white">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="black">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="assets/images/incubator-logo.svg">
</div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text">
<li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul>
</li>
      </div>

      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Fundamentals of Classification in Machine Learning
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Fundamentals of Classification in Machine Learning
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Fundamentals of Classification in Machine Learning
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text">
<li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul>
</li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->

            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="01_introduction.html">1. 01 Introduction</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="02_logistic_regression.html">2. 02 Logistic Regression</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="03_logistic_regression_optimization.html">3. 03 Logistic Regression Optimization</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="04_svm.html">4. 04 Svm</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush6">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading6">
        <a href="05_svm_optimization.html">5. 05 Svm Optimization</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush7">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading7">
        <a href="06_model_evaluation.html">6. 06 Model Evaluation</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush8">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading8">
        <a href="07_neural_networks.html">7. 07 Neural Networks</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush9">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading9">
        <a href="08_neural_networks_optimization.html">8. 08 Neural Networks Optimization</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush10">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading10">
        <a href="09_random_forest.html">9. 09 Random Forest</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush11">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading11">
        <a href="10_random_forest_optimization.html">10. 10 Random Forest Optimization</a>
    </div>
<!--/div.accordion-header-->

  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources">
<a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">

            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-01_introduction"><p>Content from <a href="01_introduction.html">01 Introduction</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/01_introduction.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="introduction-to-classification">Introduction to Classification<a class="anchor" aria-label="anchor" href="#introduction-to-classification"></a>
</h1>
<div class="section level2">
<h2 id="what-is-classification">What is Classification?<a class="anchor" aria-label="anchor" href="#what-is-classification"></a>
</h2>
<p>Classification is a type of supervised learning where the goal is to
predict categorical class labels. Given input data, a classification
model attempts to assign it to one of several predefined classes.</p>
<p>Some examples include: - Email spam detection (spam vs.Â not spam) -
Disease diagnosis (positive vs.Â negative) - Image recognition (cat, dog,
or other)</p>
</div>
<div class="section level2">
<h2 id="workshop-goals">Workshop Goals<a class="anchor" aria-label="anchor" href="#workshop-goals"></a>
</h2>
<p>By the end of this workshop, you will be able to: - Understand common
classification algorithms - Apply them using Scikit-Learn, NumPy,
Pandas, and Matplotlib - Evaluate and optimise models</p>
</div>
<div class="section level2">
<h2 id="topics-covered">Topics Covered<a class="anchor" aria-label="anchor" href="#topics-covered"></a>
</h2>
<ol style="list-style-type: decimal">
<li>Logistic Regression</li>
<li>Support Vector Machines (SVM)</li>
<li>Model Evaluation: Accuracy, Precision, Recall, F1-Score,
ROC-AUC</li>
<li>Neural Networks (MLPClassifier)</li>
<li>Random Forest Classifier</li>
<li>Optimisation and Tuning</li>
</ol>
</div>
<div class="section level2">
<h2 id="required-libraries">Required Libraries<a class="anchor" aria-label="anchor" href="#required-libraries"></a>
</h2>
<p>We will use the following Python libraries throughout the workshop: -
<code>NumPy</code> â€“ numerical operations - <code>Pandas</code> â€“ data
manipulation - <code>Scikit-Learn</code> â€“ machine learning models and
tools - <code>Matplotlib</code> â€“ data visualisation -
<code>Seaborn</code> - data visualisation</p>
<hr>
<p>Letâ€™s get started! ðŸš€</p>
<div class="section level3">
<h3 id="installing-libraries">Installing Libraries<a class="anchor" aria-label="anchor" href="#installing-libraries"></a>
</h3>
<p>Uncomment and run the commands below only if packages are not
installed.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># !pip install numpy</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># !pip install pandas</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># !pip install scikit-learn</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co"># !pip install matplotlib</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># !pip install seaborn</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="check-your-environment-has-the-necessary-libraries-installed">Check your environment has the necessary libraries installed<a class="anchor" aria-label="anchor" href="#check-your-environment-has-the-necessary-libraries-installed"></a>
</h3>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> numpy</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy version:"</span>, numpy.__version__)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="im">import</span> pandas</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pandas version:"</span>, pandas.__version__)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"sklearn version:"</span>, sklearn.__version__)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"matplotlib version:"</span>, matplotlib.__version__)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="im">import</span> seaborn</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"sklearn version:"</span>, seaborn.__version__)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">NumPy</span> version: 2.2.6</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="ex">Pandas</span> version: 2.2.3</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="ex">sklearn</span> version: 1.7.0</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="ex">matplotlib</span> version: 3.10.3</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="ex">sklearn</span> version: 0.13.2</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="preview-example-dataset">Preview Example Dataset<a class="anchor" aria-label="anchor" href="#preview-example-dataset"></a>
</h3>
<p>We use the <code>load_breast_cancer()</code> dataset from
Scikit-Learn. It includes 30 numeric features extracted from breast mass
images.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>data.feature_names)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>df[<span class="st">'target'</span>] <span class="op">=</span> y</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>df.head()</span></code></pre>
</div>
<table style="width:100%;" class="table">
<colgroup>
<col width="0%">
<col width="3%">
<col width="4%">
<col width="4%">
<col width="3%">
<col width="4%">
<col width="5%">
<col width="4%">
<col width="6%">
<col width="4%">
<col width="7%">
<col width="1%">
<col width="4%">
<col width="4%">
<col width="3%">
<col width="5%">
<col width="5%">
<col width="4%">
<col width="6%">
<col width="4%">
<col width="7%">
<col width="2%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>mean radius</th>
<th>mean texture</th>
<th>mean perimeter</th>
<th>mean area</th>
<th>mean smoothness</th>
<th>mean compactness</th>
<th>mean concavity</th>
<th>mean concave points</th>
<th>mean symmetry</th>
<th>mean fractal dimension</th>
<th>â€¦</th>
<th>worst texture</th>
<th>worst perimeter</th>
<th>worst area</th>
<th>worst smoothness</th>
<th>worst compactness</th>
<th>worst concavity</th>
<th>worst concave points</th>
<th>worst symmetry</th>
<th>worst fractal dimension</th>
<th>target</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.3001</td>
<td>0.14710</td>
<td>0.2419</td>
<td>0.07871</td>
<td>â€¦</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.1622</td>
<td>0.6656</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
<td>0</td>
</tr>
<tr class="even">
<td>1</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.0869</td>
<td>0.07017</td>
<td>0.1812</td>
<td>0.05667</td>
<td>â€¦</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.1238</td>
<td>0.1866</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
<td>0</td>
</tr>
<tr class="odd">
<td>2</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.1974</td>
<td>0.12790</td>
<td>0.2069</td>
<td>0.05999</td>
<td>â€¦</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.1444</td>
<td>0.4245</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
<td>0</td>
</tr>
<tr class="even">
<td>3</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.2414</td>
<td>0.10520</td>
<td>0.2597</td>
<td>0.09744</td>
<td>â€¦</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.2098</td>
<td>0.8663</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
<td>0</td>
</tr>
<tr class="odd">
<td>4</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.1980</td>
<td>0.10430</td>
<td>0.1809</td>
<td>0.05883</td>
<td>â€¦</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.1374</td>
<td>0.2050</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>5 rows Ã— 31 columns</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>df.describe()</span></code></pre>
</div>
<table style="width:100%;" class="table">
<colgroup>
<col width="1%">
<col width="3%">
<col width="3%">
<col width="4%">
<col width="3%">
<col width="4%">
<col width="5%">
<col width="4%">
<col width="5%">
<col width="4%">
<col width="6%">
<col width="1%">
<col width="4%">
<col width="4%">
<col width="3%">
<col width="5%">
<col width="5%">
<col width="4%">
<col width="6%">
<col width="4%">
<col width="7%">
<col width="3%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>mean radius</th>
<th>mean texture</th>
<th>mean perimeter</th>
<th>mean area</th>
<th>mean smoothness</th>
<th>mean compactness</th>
<th>mean concavity</th>
<th>mean concave points</th>
<th>mean symmetry</th>
<th>mean fractal dimension</th>
<th>â€¦</th>
<th>worst texture</th>
<th>worst perimeter</th>
<th>worst area</th>
<th>worst smoothness</th>
<th>worst compactness</th>
<th>worst concavity</th>
<th>worst concave points</th>
<th>worst symmetry</th>
<th>worst fractal dimension</th>
<th>target</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>count</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>â€¦</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
<td>569.000000</td>
</tr>
<tr class="even">
<td>mean</td>
<td>14.127292</td>
<td>19.289649</td>
<td>91.969033</td>
<td>654.889104</td>
<td>0.096360</td>
<td>0.104341</td>
<td>0.088799</td>
<td>0.048919</td>
<td>0.181162</td>
<td>0.062798</td>
<td>â€¦</td>
<td>25.677223</td>
<td>107.261213</td>
<td>880.583128</td>
<td>0.132369</td>
<td>0.254265</td>
<td>0.272188</td>
<td>0.114606</td>
<td>0.290076</td>
<td>0.083946</td>
<td>0.627417</td>
</tr>
<tr class="odd">
<td>std</td>
<td>3.524049</td>
<td>4.301036</td>
<td>24.298981</td>
<td>351.914129</td>
<td>0.014064</td>
<td>0.052813</td>
<td>0.079720</td>
<td>0.038803</td>
<td>0.027414</td>
<td>0.007060</td>
<td>â€¦</td>
<td>6.146258</td>
<td>33.602542</td>
<td>569.356993</td>
<td>0.022832</td>
<td>0.157336</td>
<td>0.208624</td>
<td>0.065732</td>
<td>0.061867</td>
<td>0.018061</td>
<td>0.483918</td>
</tr>
<tr class="even">
<td>min</td>
<td>6.981000</td>
<td>9.710000</td>
<td>43.790000</td>
<td>143.500000</td>
<td>0.052630</td>
<td>0.019380</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.106000</td>
<td>0.049960</td>
<td>â€¦</td>
<td>12.020000</td>
<td>50.410000</td>
<td>185.200000</td>
<td>0.071170</td>
<td>0.027290</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156500</td>
<td>0.055040</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td>25%</td>
<td>11.700000</td>
<td>16.170000</td>
<td>75.170000</td>
<td>420.300000</td>
<td>0.086370</td>
<td>0.064920</td>
<td>0.029560</td>
<td>0.020310</td>
<td>0.161900</td>
<td>0.057700</td>
<td>â€¦</td>
<td>21.080000</td>
<td>84.110000</td>
<td>515.300000</td>
<td>0.116600</td>
<td>0.147200</td>
<td>0.114500</td>
<td>0.064930</td>
<td>0.250400</td>
<td>0.071460</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td>50%</td>
<td>13.370000</td>
<td>18.840000</td>
<td>86.240000</td>
<td>551.100000</td>
<td>0.095870</td>
<td>0.092630</td>
<td>0.061540</td>
<td>0.033500</td>
<td>0.179200</td>
<td>0.061540</td>
<td>â€¦</td>
<td>25.410000</td>
<td>97.660000</td>
<td>686.500000</td>
<td>0.131300</td>
<td>0.211900</td>
<td>0.226700</td>
<td>0.099930</td>
<td>0.282200</td>
<td>0.080040</td>
<td>1.000000</td>
</tr>
<tr class="odd">
<td>75%</td>
<td>15.780000</td>
<td>21.800000</td>
<td>104.100000</td>
<td>782.700000</td>
<td>0.105300</td>
<td>0.130400</td>
<td>0.130700</td>
<td>0.074000</td>
<td>0.195700</td>
<td>0.066120</td>
<td>â€¦</td>
<td>29.720000</td>
<td>125.400000</td>
<td>1084.000000</td>
<td>0.146000</td>
<td>0.339100</td>
<td>0.382900</td>
<td>0.161400</td>
<td>0.317900</td>
<td>0.092080</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td>max</td>
<td>28.110000</td>
<td>39.280000</td>
<td>188.500000</td>
<td>2501.000000</td>
<td>0.163400</td>
<td>0.345400</td>
<td>0.426800</td>
<td>0.201200</td>
<td>0.304000</td>
<td>0.097440</td>
<td>â€¦</td>
<td>49.540000</td>
<td>251.200000</td>
<td>4254.000000</td>
<td>0.222600</td>
<td>1.058000</td>
<td>1.252000</td>
<td>0.291000</td>
<td>0.663800</td>
<td>0.207500</td>
<td>1.000000</td>
</tr>
</tbody>
</table>
<p>8 rows Ã— 31 columns</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>df.hist(bins<span class="op">=</span><span class="dv">20</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">10</span>))</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>plt.tight_layout()</span></code></pre>
</div>
<figure><img src="01_introduction/output_10_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Apply StandardScaler</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>df_scaled <span class="op">=</span> pd.DataFrame(scaler.fit_transform(df), columns<span class="op">=</span>df.columns, index<span class="op">=</span>df.index)</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>df_scaled.describe()</span></code></pre>
</div>
<table style="width:100%;" class="table">
<colgroup>
<col width="1%">
<col width="4%">
<col width="4%">
<col width="4%">
<col width="4%">
<col width="4%">
<col width="5%">
<col width="4%">
<col width="5%">
<col width="4%">
<col width="6%">
<col width="1%">
<col width="4%">
<col width="4%">
<col width="3%">
<col width="5%">
<col width="5%">
<col width="4%">
<col width="6%">
<col width="4%">
<col width="6%">
<col width="4%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>mean radius</th>
<th>mean texture</th>
<th>mean perimeter</th>
<th>mean area</th>
<th>mean smoothness</th>
<th>mean compactness</th>
<th>mean concavity</th>
<th>mean concave points</th>
<th>mean symmetry</th>
<th>mean fractal dimension</th>
<th>â€¦</th>
<th>worst texture</th>
<th>worst perimeter</th>
<th>worst area</th>
<th>worst smoothness</th>
<th>worst compactness</th>
<th>worst concavity</th>
<th>worst concave points</th>
<th>worst symmetry</th>
<th>worst fractal dimension</th>
<th>target</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>count</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>â€¦</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>569.000000</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
<td>5.690000e+02</td>
</tr>
<tr class="even">
<td>mean</td>
<td>-1.373633e-16</td>
<td>6.868164e-17</td>
<td>-1.248757e-16</td>
<td>-2.185325e-16</td>
<td>-8.366672e-16</td>
<td>1.873136e-16</td>
<td>4.995028e-17</td>
<td>-4.995028e-17</td>
<td>1.748260e-16</td>
<td>4.745277e-16</td>
<td>â€¦</td>
<td>1.248757e-17</td>
<td>-3.746271e-16</td>
<td>0.000000</td>
<td>-2.372638e-16</td>
<td>-3.371644e-16</td>
<td>7.492542e-17</td>
<td>2.247763e-16</td>
<td>2.622390e-16</td>
<td>-5.744282e-16</td>
<td>-4.995028e-17</td>
</tr>
<tr class="odd">
<td>std</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>â€¦</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
<td>1.000880e+00</td>
</tr>
<tr class="even">
<td>min</td>
<td>-2.029648e+00</td>
<td>-2.229249e+00</td>
<td>-1.984504e+00</td>
<td>-1.454443e+00</td>
<td>-3.112085e+00</td>
<td>-1.610136e+00</td>
<td>-1.114873e+00</td>
<td>-1.261820e+00</td>
<td>-2.744117e+00</td>
<td>-1.819865e+00</td>
<td>â€¦</td>
<td>-2.223994e+00</td>
<td>-1.693361e+00</td>
<td>-1.222423</td>
<td>-2.682695e+00</td>
<td>-1.443878e+00</td>
<td>-1.305831e+00</td>
<td>-1.745063e+00</td>
<td>-2.160960e+00</td>
<td>-1.601839e+00</td>
<td>-1.297676e+00</td>
</tr>
<tr class="odd">
<td>25%</td>
<td>-6.893853e-01</td>
<td>-7.259631e-01</td>
<td>-6.919555e-01</td>
<td>-6.671955e-01</td>
<td>-7.109628e-01</td>
<td>-7.470860e-01</td>
<td>-7.437479e-01</td>
<td>-7.379438e-01</td>
<td>-7.032397e-01</td>
<td>-7.226392e-01</td>
<td>â€¦</td>
<td>-7.486293e-01</td>
<td>-6.895783e-01</td>
<td>-0.642136</td>
<td>-6.912304e-01</td>
<td>-6.810833e-01</td>
<td>-7.565142e-01</td>
<td>-7.563999e-01</td>
<td>-6.418637e-01</td>
<td>-6.919118e-01</td>
<td>-1.297676e+00</td>
</tr>
<tr class="even">
<td>50%</td>
<td>-2.150816e-01</td>
<td>-1.046362e-01</td>
<td>-2.359800e-01</td>
<td>-2.951869e-01</td>
<td>-3.489108e-02</td>
<td>-2.219405e-01</td>
<td>-3.422399e-01</td>
<td>-3.977212e-01</td>
<td>-7.162650e-02</td>
<td>-1.782793e-01</td>
<td>â€¦</td>
<td>-4.351564e-02</td>
<td>-2.859802e-01</td>
<td>-0.341181</td>
<td>-4.684277e-02</td>
<td>-2.695009e-01</td>
<td>-2.182321e-01</td>
<td>-2.234689e-01</td>
<td>-1.274095e-01</td>
<td>-2.164441e-01</td>
<td>7.706085e-01</td>
</tr>
<tr class="odd">
<td>75%</td>
<td>4.693926e-01</td>
<td>5.841756e-01</td>
<td>4.996769e-01</td>
<td>3.635073e-01</td>
<td>6.361990e-01</td>
<td>4.938569e-01</td>
<td>5.260619e-01</td>
<td>6.469351e-01</td>
<td>5.307792e-01</td>
<td>4.709834e-01</td>
<td>â€¦</td>
<td>6.583411e-01</td>
<td>5.402790e-01</td>
<td>0.357589</td>
<td>5.975448e-01</td>
<td>5.396688e-01</td>
<td>5.311411e-01</td>
<td>7.125100e-01</td>
<td>4.501382e-01</td>
<td>4.507624e-01</td>
<td>7.706085e-01</td>
</tr>
<tr class="even">
<td>max</td>
<td>3.971288e+00</td>
<td>4.651889e+00</td>
<td>3.976130e+00</td>
<td>5.250529e+00</td>
<td>4.770911e+00</td>
<td>4.568425e+00</td>
<td>4.243589e+00</td>
<td>3.927930e+00</td>
<td>4.484751e+00</td>
<td>4.910919e+00</td>
<td>â€¦</td>
<td>3.885905e+00</td>
<td>4.287337e+00</td>
<td>5.930172</td>
<td>3.955374e+00</td>
<td>5.112877e+00</td>
<td>4.700669e+00</td>
<td>2.685877e+00</td>
<td>6.046041e+00</td>
<td>6.846856e+00</td>
<td>7.706085e-01</td>
</tr>
</tbody>
</table>
<p>8 rows Ã— 31 columns</p>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-02_logistic_regression"><p>Content from <a href="02_logistic_regression.html">02 Logistic Regression</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/02_logistic_regression.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="logistic-regression-with-breast-cancer-dataset">Logistic Regression with Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#logistic-regression-with-breast-cancer-dataset"></a>
</h1>
<p>This notebook demonstrates how to use <strong>Logistic
Regression</strong>, a fundamental classification algorithm, to predict
whether a tumor is malignant or benign using the Breast Cancer Wisconsin
dataset.</p>
<div class="section level2">
<h2 id="what-is-logistic-regression">What is Logistic Regression?<a class="anchor" aria-label="anchor" href="#what-is-logistic-regression"></a>
</h2>
<p>Logistic Regression is a <strong>supervised learning</strong>
algorithm used for <strong>binary classification</strong>.</p>
<p>It models the probability that an input <span class="math inline">\(\mathbf{x}\)</span> belongs to class <span class="math inline">\(y=1\)</span> using the <strong>logistic
(sigmoid)</strong> function:</p>
<p><span class="math display">\[
P(y=1 | \mathbf{x}) = \frac{1}{1 + e^{- (\mathbf{w}^T \mathbf{x} + b)}}
\]</span></p>
<p>The output is a probability between 0 and 1. We classify an
observation as class <code>1</code> if the predicted probability exceeds
a threshold (typically 0.5).</p>
</div>
<div class="section level2">
<h2 id="step-1-load-and-explore-the-data">Step 1: Load and Explore the Data<a class="anchor" aria-label="anchor" href="#step-1-load-and-explore-the-data"></a>
</h2>
<p>We use the <code>load_breast_cancer()</code> dataset from
Scikit-Learn. It includes 30 numeric features extracted from breast mass
images.</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-split-the-data-and-train-the-model">Step 3: Split the Data and Train the Model<a class="anchor" aria-label="anchor" href="#step-3-split-the-data-and-train-the-model"></a>
</h2>
<p>We split the dataset into training and testing sets, and fit a
logistic regression model.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>model.fit(X_train, y_train)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-4-evaluate-the-model">Step 4: Evaluate the Model<a class="anchor" aria-label="anchor" href="#step-4-evaluate-the-model"></a>
</h2>
<p><strong>Metrics Used:</strong> - Accuracy - Precision - Recall -
F1-score - Confusion Matrix - ROC Curve and AUC</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    classification_report,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(y_test, y_pred))</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Precision:"</span>, precision_score(y_test, y_pred))</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Recall:"</span>, recall_score(y_test, y_pred))</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score:"</span>, f1_score(y_test, y_pred))</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred))</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">Accuracy:</span> 0.9766081871345029</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="ex">Precision:</span> 0.981651376146789</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="ex">Recall:</span> 0.981651376146789</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="ex">F1</span> Score: 0.981651376146789</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="ex">Classification</span> Report:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>               <span class="ex">precision</span>    recall  f1-score   support</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>           <span class="ex">0</span>       0.97      0.97      0.97        62</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>           <span class="ex">1</span>       0.98      0.98      0.98       109</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    <span class="ex">accuracy</span>                           0.98       171</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>   <span class="ex">macro</span> avg       0.97      0.97      0.97       171</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="ex">weighted</span> avg       0.98      0.98      0.98       171</span></code></pre>
</div>
<div class="section level3">
<h3 id="what-is-a-confusion-matrix">What is a Confusion Matrix?<a class="anchor" aria-label="anchor" href="#what-is-a-confusion-matrix"></a>
</h3>
<p>A <strong>confusion matrix</strong> is a table used to describe the
performance of a classification model. For binary classification:</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Actual Positive</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr class="even">
<td>Actual Negative</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<ul>
<li>
<strong>Accuracy</strong> = (TP + TN) / (TP + TN + FP + FN)<br>
</li>
<li>
<strong>Precision</strong> = TP / (TP + FP)<br>
</li>
<li>
<strong>Recall (Sensitivity)</strong> = TP / (TP + FN)<br>
</li>
<li>
<strong>F1 Score</strong> = 2 * (Precision * Recall) / (Precision +
Recall)</li>
</ul>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="02_logistic_regression/output_10_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level3">
<h3 id="what-is-an-roc-curve">What is an ROC Curve?<a class="anchor" aria-label="anchor" href="#what-is-an-roc-curve"></a>
</h3>
<p>An <strong>ROC Curve</strong> (Receiver Operating Characteristic)
plots:</p>
<ul>
<li>
<strong>True Positive Rate (Recall)</strong> on the Y-axis</li>
<li>
<strong>False Positive Rate (1 - Specificity)</strong> on the
X-axis</li>
</ul>
<p>Each point on the curve corresponds to a different classification
threshold. A model with perfect classification has a point in the
top-left corner.</p>
<p><strong>AUC (Area Under Curve)</strong> summarizes the ROC curve into
a single value between 0 and 1: - AUC = 1: Perfect classifier - AUC =
0.5: No better than random guessing</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_proba)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="st">'AUC = '</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">round</span>(roc_auc, <span class="dv">2</span>)))</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>plt.title(<span class="st">'ROC Curve'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="02_logistic_regression/output_12_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-03_logistic_regression_optimization"><p>Content from <a href="03_logistic_regression_optimization.html">03 Logistic Regression Optimization</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/03_logistic_regression_optimization.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="optimising-a-logistic-regression-classifier">Optimising a Logistic Regression Classifier<a class="anchor" aria-label="anchor" href="#optimising-a-logistic-regression-classifier"></a>
</h1>
<p>In this notebook, we demonstrate how to <strong>tune
hyperparameters</strong> in a Logistic Regression model to improve
performance.</p>
<div class="section level2">
<h2 id="step-1-load-breast-cancer-data">Step 1: Load Breast Cancer Data<a class="anchor" aria-label="anchor" href="#step-1-load-breast-cancer-data"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-2-define-a-function-to-train-and-evaluate">Step 2: Define a Function to Train and Evaluate<a class="anchor" aria-label="anchor" href="#step-2-define-a-function-to-train-and-evaluate"></a>
</h2>
<p>This function will: - Train the model - Return training and test
accuracy</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="kw">def</span> train_and_evaluate(max_iter<span class="op">=</span><span class="dv">5000</span>, C<span class="op">=</span><span class="dv">1</span>, penalty<span class="op">=</span><span class="st">'l2'</span>, solver<span class="op">=</span><span class="st">'liblinear'</span>):</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    model <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span>max_iter, C<span class="op">=</span>C, penalty<span class="op">=</span>penalty, solver<span class="op">=</span>solver)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>    <span class="cf">return</span> train_acc, test_acc</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-explore-effect-of-c-inverse-of-regularization-strength">Step 3: Explore Effect of C (Inverse of Regularization
Strength)<a class="anchor" aria-label="anchor" href="#step-3-explore-effect-of-c-inverse-of-regularization-strength"></a>
</h2>
<p>Controls the amount of regularization. Effect:</p>
<p>Smaller C â†’ Stronger regularization â†’ Prevents overfitting but may
underfit.</p>
<p>Larger C â†’ Weaker regularization â†’ Better fit but may overfit.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>values <span class="op">=</span> [ <span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span> ]</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>train_scores, test_scores <span class="op">=</span> [], []</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="cf">for</span> v <span class="kw">in</span> values:</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    tr, te <span class="op">=</span> train_and_evaluate(C<span class="op">=</span>v)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    train_scores.append(tr)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    test_scores.append(te)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>labels <span class="op">=</span> [<span class="bu">str</span>(s) <span class="cf">for</span> s <span class="kw">in</span> values]</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>plt.plot(labels, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Acc'</span>)</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>plt.plot(labels, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Acc'</span>)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>plt.xlabel(<span class="st">'Values'</span>)</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="03_logistic_regression_optimization/output_6_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="step-4-explore-effect-of-penalty-l1-l2-regularization">Step 4: Explore Effect of <code>penalty</code> (L1, L2
Regularization)<a class="anchor" aria-label="anchor" href="#step-4-explore-effect-of-penalty-l1-l2-regularization"></a>
</h2>
<table class="table">
<colgroup>
<col width="7%">
<col width="30%">
<col width="62%">
</colgroup>
<thead><tr class="header">
<th>Penalty</th>
<th>Key Effect</th>
<th>When to Use</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>L1</td>
<td>Sparsity, feature selection</td>
<td>You want simpler models or auto-feature selection</td>
</tr>
<tr class="even">
<td>L2</td>
<td>Shrinkage, no sparsity</td>
<td>You want to reduce overfitting without dropping features</td>
</tr>
</tbody>
</table>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>values <span class="op">=</span> [ <span class="st">'l1'</span>, <span class="st">'l2'</span> ]</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>train_scores, test_scores <span class="op">=</span> [], []</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="cf">for</span> v <span class="kw">in</span> values:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    tr, te <span class="op">=</span> train_and_evaluate(penalty<span class="op">=</span>v)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    train_scores.append(tr)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    test_scores.append(te)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>labels <span class="op">=</span> [<span class="bu">str</span>(s) <span class="cf">for</span> s <span class="kw">in</span> values]</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>plt.plot(labels, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Acc'</span>)</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>plt.plot(labels, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Acc'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>plt.xlabel(<span class="st">'Values'</span>)</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="03_logistic_regression_optimization/output_8_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="step-5-explore-effect-of-max_iter">Step 5: Explore Effect of <code>max_iter</code>
<a class="anchor" aria-label="anchor" href="#step-5-explore-effect-of-max_iter"></a>
</h2>
<table class="table">
<colgroup>
<col width="15%">
<col width="84%">
</colgroup>
<thead><tr class="header">
<th><strong>Scenario</strong></th>
<th><strong>Effect</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Too <strong>low</strong>
</td>
<td>Model may <strong>not converge</strong> â†’ Youâ€™ll see warnings like
â€œSTOP: TOTAL NO. OF F, G EVALUATIONS EXCEEDS LIMITâ€. Model coefficients
may be inaccurate or unstable.</td>
</tr>
<tr class="even">
<td>Sufficient (or slightly high)</td>
<td>Model <strong>converges properly</strong>. No warnings. Coefficients
stabilize at optimal values.</td>
</tr>
<tr class="odd">
<td>Very <strong>high</strong> (but converges early)</td>
<td>No harmâ€”most solvers <strong>stop automatically</strong> once
convergence is reached (before hitting <code>max_iter</code>). However,
unnecessarily large values can increase training time for very large
datasets.</td>
</tr>
</tbody>
</table>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>values <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">10</span>, <span class="dv">100</span> ]</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>train_scores, test_scores <span class="op">=</span> [], []</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="cf">for</span> v <span class="kw">in</span> values:</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    tr, te <span class="op">=</span> train_and_evaluate(max_iter<span class="op">=</span>v)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>    train_scores.append(tr)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    test_scores.append(te)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>labels <span class="op">=</span> [<span class="bu">str</span>(s) <span class="cf">for</span> s <span class="kw">in</span> values]</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>plt.plot(labels, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Acc'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>plt.plot(labels, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Acc'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>plt.xlabel(<span class="st">'Values'</span>)</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">C:\Users\moji1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sklearn\svm\_base.py:1250:</span> ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>  <span class="ex">warnings.warn</span><span class="er">(</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="ex">C:\Users\moji1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sklearn\svm\_base.py:1250:</span> ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>  <span class="ex">warnings.warn</span><span class="er">(</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="ex">C:\Users\moji1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sklearn\svm\_base.py:1250:</span> ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>  <span class="ex">warnings.warn</span><span class="er">(</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="ex">C:\Users\moji1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sklearn\svm\_base.py:1250:</span> ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>  <span class="ex">warnings.warn</span><span class="er">(</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="ex">C:\Users\moji1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sklearn\svm\_base.py:1250:</span> ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>  <span class="ex">warnings.warn</span><span class="er">(</span></span></code></pre>
</div>
<figure><img src="03_logistic_regression_optimization/output_10_1.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="changing-the-classification-threshold">Changing the Classification Threshold<a class="anchor" aria-label="anchor" href="#changing-the-classification-threshold"></a>
</h2>
<p>Most classifiers output probabilities between 0 and 1. By default,
the threshold for classification is 0.5. This means:</p>
<ul>
<li>If predicted probability â‰¥ 0.5 â†’ classify as
<strong>positive</strong>
</li>
<li>Else â†’ classify as <strong>negative</strong>
</li>
</ul>
<div class="section level3">
<h3 id="changing-the-threshold">Changing the Threshold:<a class="anchor" aria-label="anchor" href="#changing-the-threshold"></a>
</h3>
<ul>
<li>
<strong>Lower threshold</strong> â†’ more positives predicted â†’ higher
<strong>recall</strong>, more <strong>false positives</strong>
</li>
<li>
<strong>Higher threshold</strong> â†’ fewer positives predicted â†’
higher <strong>precision</strong>, more <strong>false
negatives</strong>
</li>
</ul>
<p>Choosing the right threshold depends on your applicationâ€™s goals.</p>
<p>Weâ€™ll now visualize how the confusion matrix changes for <strong>two
different thresholds</strong>.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>thresholds <span class="op">=</span> [<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>]         <span class="co"># List of three thresholds to compare</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co"># Retrain model</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>manual_model <span class="op">=</span> LogisticRegression()</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>manual_model.fit(X_train, y_train)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co"># Predict probabilities</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>y_proba <span class="op">=</span> manual_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co"># Plot side-by-side confusion matrices</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="cf">for</span> i, thresh <span class="kw">in</span> <span class="bu">enumerate</span>(thresholds):</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    y_pred <span class="op">=</span> (y_proba <span class="op">&amp;</span>gt<span class="op">;=</span> thresh).astype(<span class="bu">int</span>)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax<span class="op">=</span>axs[i])</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    axs[i].set_title(<span class="ss">f"Threshold = </span><span class="sc">{</span>thresh<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="03_logistic_regression_optimization/output_12_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-04_svm"><p>Content from <a href="04_svm.html">04 Svm</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/04_svm.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="support-vector-machine-svm-with-breast-cancer-dataset">Support Vector Machine (SVM) with Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#support-vector-machine-svm-with-breast-cancer-dataset"></a>
</h1>
<p>This notebook demonstrates the use of <strong>Support Vector Machines
(SVM)</strong> for classifying tumors in the Breast Cancer dataset.</p>
<div class="section level2">
<h2 id="what-is-an-svm">What is an SVM?<a class="anchor" aria-label="anchor" href="#what-is-an-svm"></a>
</h2>
<p>Support Vector Machines are powerful supervised learning models for
classification. An SVM finds the <strong>hyperplane</strong> that best
separates data points from two classes.</p>
<p>It maximizes the <strong>margin</strong>, which is the distance
between the hyperplane and the nearest points from each class (support
vectors).</p>
</div>
<div class="section level2">
<h2 id="step-1-load-the-breast-cancer-dataset">Step 1: Load the Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#step-1-load-the-breast-cancer-dataset"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-train-an-svm-model">Step 3: Train an SVM Model<a class="anchor" aria-label="anchor" href="#step-3-train-an-svm-model"></a>
</h2>
<p>We use the <code>SVC</code> class from <code>sklearn.svm</code> with
default kernel (RBF).</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>model <span class="op">=</span> SVC(probability<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>model.fit(X_train, y_train)</span></code></pre>
</div>
<p>#sk-container-id-1 { /* Definition of color scheme common for light
and dark mode <em>/ â€“sklearn-color-text: #000;
â€“sklearn-color-text-muted: #666; â€“sklearn-color-line: gray; /</em>
Definition of color scheme for unfitted estimators <em>/
â€“sklearn-color-unfitted-level-0: #fff5e6;
â€“sklearn-color-unfitted-level-1: #f6e4d2;
â€“sklearn-color-unfitted-level-2: #ffe0b3;
â€“sklearn-color-unfitted-level-3: chocolate; /</em> Definition of color
scheme for fitted estimators */ â€“sklearn-color-fitted-level-0: #f0f8ff;
â€“sklearn-color-fitted-level-1: #d4ebff; â€“sklearn-color-fitted-level-2:
#b3dbfd; â€“sklearn-color-fitted-level-3: cornflowerblue;</p>
<p>/* Specific color for light theme */
â€“sklearn-color-text-on-default-background: var(â€“sg-text-color,
var(â€“theme-code-foreground, var(â€“jp-content-font-color1, black)));
â€“sklearn-color-background: var(â€“sg-background-color,
var(â€“theme-background, var(â€“jp-layout-color0, white)));
â€“sklearn-color-border-box: var(â€“sg-text-color,
var(â€“theme-code-foreground, var(â€“jp-content-font-color1, black)));
â€“sklearn-color-icon: #696969;</p>
<p><span class="citation">@media</span> (prefers-color-scheme: dark) {
/* Redefinition of color scheme for dark theme */
â€“sklearn-color-text-on-default-background: var(â€“sg-text-color,
var(â€“theme-code-foreground, var(â€“jp-content-font-color1, white)));
â€“sklearn-color-background: var(â€“sg-background-color,
var(â€“theme-background, var(â€“jp-layout-color0, #111)));
â€“sklearn-color-border-box: var(â€“sg-text-color,
var(â€“theme-code-foreground, var(â€“jp-content-font-color1, white)));
â€“sklearn-color-icon: #878787; } }</p>
<p>#sk-container-id-1 { color: var(â€“sklearn-color-text); }</p>
<p>#sk-container-id-1 pre { padding: 0; }</p>
<p>#sk-container-id-1 input.sk-hiddenâ€“visually { border: 0; clip:
rect(1px 1px 1px 1px); clip: rect(1px, 1px, 1px, 1px); height: 1px;
margin: -1px; overflow: hidden; padding: 0; position: absolute; width:
1px; }</p>
<p>#sk-container-id-1 div.sk-dashed-wrapped { border: 1px dashed
var(â€“sklearn-color-line); margin: 0 0.4em 0.5em 0.4em; box-sizing:
border-box; padding-bottom: 0.4em; background-color:
var(â€“sklearn-color-background); }</p>
<p>#sk-container-id-1 div.sk-container { /* jupyterâ€™s
<code>normalize.less</code> sets
<code>[hidden] { display: none; }</code> but bootstrap.min.css set
<code>[hidden] { display: none !important; }</code> so we also need the
<code>!important</code> here to be able to override the default hidden
behavior on the sphinx rendered scikit-learn.org. See: <a href="https://github.com/scikit-learn/scikit-learn/issues/21755" class="external-link uri">https://github.com/scikit-learn/scikit-learn/issues/21755</a>
*/ display: inline-block !important; position: relative; }</p>
<p>#sk-container-id-1 div.sk-text-repr-fallback { display: none; }</p>
<p>div.sk-parallel-item, div.sk-serial, div.sk-item { /* draw centered
vertical line to link estimators */ background-image:
linear-gradient(var(â€“sklearn-color-text-on-default-background),
var(â€“sklearn-color-text-on-default-background)); background-size: 2px
100%; background-repeat: no-repeat; background-position: center center;
}</p>
<p>/* Parallel-specific style estimator block */</p>
<p>#sk-container-id-1 div.sk-parallel-item::after { content: â€œâ€œ; width:
100%; border-bottom: 2px solid
var(â€“sklearn-color-text-on-default-background); flex-grow: 1; }</p>
<p>#sk-container-id-1 div.sk-parallel { display: flex; align-items:
stretch; justify-content: center; background-color:
var(â€“sklearn-color-background); position: relative; }</p>
<p>#sk-container-id-1 div.sk-parallel-item { display: flex;
flex-direction: column; }</p>
<p>#sk-container-id-1 div.sk-parallel-item:first-child::after {
align-self: flex-end; width: 50%; }</p>
<p>#sk-container-id-1 div.sk-parallel-item:last-child::after {
align-self: flex-start; width: 50%; }</p>
<p>#sk-container-id-1 div.sk-parallel-item:only-child::after { width: 0;
}</p>
<p>/* Serial-specific style estimator block */</p>
<p>#sk-container-id-1 div.sk-serial { display: flex; flex-direction:
column; align-items: center; background-color:
var(â€“sklearn-color-background); padding-right: 1em; padding-left: 1em;
}</p>
<p>/* Toggleable style: style used for
estimator/Pipeline/ColumnTransformer box that is clickable and can be
expanded/collapsed. - Pipeline and ColumnTransformer use this feature
and define the default style - Estimators will overwrite some part of
the style using the <code>sk-estimator</code> class */</p>
<p>/* Pipeline and ColumnTransformer style (default) */</p>
<p>#sk-container-id-1 div.sk-toggleable { /* Default theme specific
background. It is overwritten whether we have a specific estimator or a
Pipeline/ColumnTransformer */ background-color:
var(â€“sklearn-color-background); }</p>
<p>/* Toggleable label */ #sk-container-id-1 label.sk-toggleable__label
{ cursor: pointer; display: flex; width: 100%; margin-bottom: 0;
padding: 0.5em; box-sizing: border-box; text-align: center; align-items:
start; justify-content: space-between; gap: 0.5em; }</p>
<p>#sk-container-id-1 label.sk-toggleable__label .caption { font-size:
0.6rem; font-weight: lighter; color: var(â€“sklearn-color-text-muted);
}</p>
<p>#sk-container-id-1 label.sk-toggleable__label-arrow:before { /* Arrow
on the left of the label */ content: â€œâ–¸â€; float: left; margin-right:
0.25em; color: var(â€“sklearn-color-icon); }</p>
<p>#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
color: var(â€“sklearn-color-text); }</p>
<p>/* Toggleable content - dropdown */</p>
<p>#sk-container-id-1 div.sk-toggleable__content { display: none;
text-align: left; /* unfitted */ background-color:
var(â€“sklearn-color-unfitted-level-0); }</p>
<p>#sk-container-id-1 div.sk-toggleable__content.fitted { /* fitted */
background-color: var(â€“sklearn-color-fitted-level-0); }</p>
<p>#sk-container-id-1 div.sk-toggleable__content pre { margin: 0.2em;
border-radius: 0.25em; color: var(â€“sklearn-color-text); /* unfitted */
background-color: var(â€“sklearn-color-unfitted-level-0); }</p>
<p>#sk-container-id-1 div.sk-toggleable__content.fitted pre { /*
unfitted */ background-color: var(â€“sklearn-color-fitted-level-0); }</p>
<p>#sk-container-id-1
input.sk-toggleable__control:checked~div.sk-toggleable__content { /*
Expand drop-down */ display: block; width: 100%; overflow: visible;
}</p>
<p>#sk-container-id-1
input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before
{ content: â€œâ–¾â€; }</p>
<p>/* Pipeline/ColumnTransformer-specific style */</p>
<p>#sk-container-id-1 div.sk-label
input.sk-toggleable__control:checked~label.sk-toggleable__label { color:
var(â€“sklearn-color-text); background-color:
var(â€“sklearn-color-unfitted-level-2); }</p>
<p>#sk-container-id-1 div.sk-label.fitted
input.sk-toggleable__control:checked~label.sk-toggleable__label {
background-color: var(â€“sklearn-color-fitted-level-2); }</p>
<p>/* Estimator-specific style */</p>
<p>/* Colorize estimator box */ #sk-container-id-1 div.sk-estimator
input.sk-toggleable__control:checked~label.sk-toggleable__label { /*
unfitted */ background-color: var(â€“sklearn-color-unfitted-level-2);
}</p>
<p>#sk-container-id-1 div.sk-estimator.fitted
input.sk-toggleable__control:checked~label.sk-toggleable__label { /*
fitted */ background-color: var(â€“sklearn-color-fitted-level-2); }</p>
<p>#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label { /* The background is the default
theme color */ color: var(â€“sklearn-color-text-on-default-background);
}</p>
<p>/* On hover, darken the color of the background */ #sk-container-id-1
div.sk-label:hover label.sk-toggleable__label { color:
var(â€“sklearn-color-text); background-color:
var(â€“sklearn-color-unfitted-level-2); }</p>
<p>/* Label box, darken color on hover, fitted */ #sk-container-id-1
div.sk-label.fitted:hover label.sk-toggleable__label.fitted { color:
var(â€“sklearn-color-text); background-color:
var(â€“sklearn-color-fitted-level-2); }</p>
<p>/* Estimator label */</p>
<p>#sk-container-id-1 div.sk-label label { font-family: monospace;
font-weight: bold; display: inline-block; line-height: 1.2em; }</p>
<p>#sk-container-id-1 div.sk-label-container { text-align: center; }</p>
<p>/* Estimator-specific <em>/ #sk-container-id-1 div.sk-estimator {
font-family: monospace; border: 1px dotted
var(â€“sklearn-color-border-box); border-radius: 0.25em; box-sizing:
border-box; margin-bottom: 0.5em; /</em> unfitted */ background-color:
var(â€“sklearn-color-unfitted-level-0); }</p>
<p>#sk-container-id-1 div.sk-estimator.fitted { /* fitted */
background-color: var(â€“sklearn-color-fitted-level-0); }</p>
<p>/* on hover <em>/ #sk-container-id-1 div.sk-estimator:hover { /</em>
unfitted */ background-color: var(â€“sklearn-color-unfitted-level-2);
}</p>
<p>#sk-container-id-1 div.sk-estimator.fitted:hover { /* fitted */
background-color: var(â€“sklearn-color-fitted-level-2); }</p>
<p>/* Specification for estimator info (e.g.Â â€œiâ€ and â€œ?â€) */</p>
<p>/* Common style for â€œiâ€ and â€œ?â€ */</p>
<p>.sk-estimator-doc-link, a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link { float: right; font-size: smaller;
line-height: 1em; font-family: monospace; background-color:
var(â€“sklearn-color-background); border-radius: 1em; height: 1em; width:
1em; text-decoration: none !important; margin-left: 0.5em; text-align:
center; /* unfitted */ border: var(â€“sklearn-color-unfitted-level-1) 1pt
solid; color: var(â€“sklearn-color-unfitted-level-1); }</p>
<p>.sk-estimator-doc-link.fitted, a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted { /* fitted */ border:
var(â€“sklearn-color-fitted-level-1) 1pt solid; color:
var(â€“sklearn-color-fitted-level-1); }</p>
<p>/* On hover <em>/ div.sk-estimator:hover
.sk-estimator-doc-link:hover, .sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover { /</em> unfitted */ background-color:
var(â€“sklearn-color-unfitted-level-3); color:
var(â€“sklearn-color-background); text-decoration: none; }</p>
<p>div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover, div.sk-label-container:hover
.sk-estimator-doc-link.fitted:hover, .sk-estimator-doc-link.fitted:hover
{ /* fitted */ background-color: var(â€“sklearn-color-fitted-level-3);
color: var(â€“sklearn-color-background); text-decoration: none; }</p>
<p>/* Span, style for the box shown on hovering the info icon <em>/
.sk-estimator-doc-link span { display: none; z-index: 9999; position:
relative; font-weight: normal; right: .2ex; padding: .5ex; margin: .5ex;
width: min-content; min-width: 20ex; max-width: 50ex; color:
var(â€“sklearn-color-text); box-shadow: 2pt 2pt 4pt #999; /</em> unfitted
*/ background: var(â€“sklearn-color-unfitted-level-0); border: .5pt solid
var(â€“sklearn-color-unfitted-level-3); }</p>
<p>.sk-estimator-doc-link.fitted span { /* fitted */ background:
var(â€“sklearn-color-fitted-level-0); border:
var(â€“sklearn-color-fitted-level-3); }</p>
<p>.sk-estimator-doc-link:hover span { display: block; }</p>
<p>/* â€œ?â€-specific style due to the `` HTML tag */</p>
<p>#sk-container-id-1 a.estimator_doc_link { float: right; font-size:
1rem; line-height: 1em; font-family: monospace; background-color:
var(â€“sklearn-color-background); border-radius: 1rem; height: 1rem;
width: 1rem; text-decoration: none; /* unfitted */ color:
var(â€“sklearn-color-unfitted-level-1); border:
var(â€“sklearn-color-unfitted-level-1) 1pt solid; }</p>
<p>#sk-container-id-1 a.estimator_doc_link.fitted { /* fitted */ border:
var(â€“sklearn-color-fitted-level-1) 1pt solid; color:
var(â€“sklearn-color-fitted-level-1); }</p>
<p>/* On hover <em>/ #sk-container-id-1 a.estimator_doc_link:hover {
/</em> unfitted */ background-color:
var(â€“sklearn-color-unfitted-level-3); color:
var(â€“sklearn-color-background); text-decoration: none; }</p>
<p>#sk-container-id-1 a.estimator_doc_link.fitted:hover { /* fitted */
background-color: var(â€“sklearn-color-fitted-level-3); }</p>
<p>.estimator-table summary { padding: .5rem; font-family: monospace;
cursor: pointer; }</p>
<p>.estimator-table details[open] { padding-left: 0.1rem; padding-right:
0.1rem; padding-bottom: 0.3rem; }</p>
<p>.estimator-table .parameters-table { margin-left: auto !important;
margin-right: auto !important; }</p>
<p>.estimator-table .parameters-table tr:nth-child(odd) {
background-color: #fff; }</p>
<p>.estimator-table .parameters-table tr:nth-child(even) {
background-color: #f6f6f6; }</p>
<p>.estimator-table .parameters-table tr:hover { background-color:
#e0e0e0; }</p>
<p>.estimator-table table td { border: 1px solid rgba(106, 105, 104,
0.232); }</p>
<p>.user-set td { color:rgb(255, 94, 0); text-align: left; }</p>
<p>.user-set td.value pre { color:rgb(255, 94, 0) !important;
background-color: transparent !important; }</p>
<p>.default td { color: black; text-align: left; }</p>
<p>.user-set td i, .default td i { color: black; }</p>
<p>.copy-paste-icon { background-image: url(<a href="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=" class="uri">data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=</a>);
background-repeat: no-repeat; background-size: 14px 14px;
background-position: 0; display: inline-block; width: 14px; height:
14px; cursor: pointer; } SVC(probability=True)In a Jupyter environment,
please rerun this cell to show the HTML representation or trust the
notebook. On GitHub, the HTML representation is unable to render, please
try loading this page with nbviewer.org.SVC?Documentation for
SVCiFitted</p>
<p>Parameters</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th>C</th>
<th>1.0</th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td>kernel</td>
<td>â€˜rbfâ€™</td>
</tr>
<tr class="even">
<td></td>
<td>degree</td>
<td>3</td>
</tr>
<tr class="odd">
<td></td>
<td>gamma</td>
<td>â€˜scaleâ€™</td>
</tr>
<tr class="even">
<td></td>
<td>coef0</td>
<td>0.0</td>
</tr>
<tr class="odd">
<td></td>
<td>shrinking</td>
<td>True</td>
</tr>
<tr class="even">
<td></td>
<td>probability</td>
<td>True</td>
</tr>
<tr class="odd">
<td></td>
<td>tol</td>
<td>0.001</td>
</tr>
<tr class="even">
<td></td>
<td>cache_size</td>
<td>200</td>
</tr>
<tr class="odd">
<td></td>
<td>class_weight</td>
<td>None</td>
</tr>
<tr class="even">
<td></td>
<td>verbose</td>
<td>False</td>
</tr>
<tr class="odd">
<td></td>
<td>max_iter</td>
<td>-1</td>
</tr>
<tr class="even">
<td></td>
<td>decision_function_shape</td>
<td>â€˜ovrâ€™</td>
</tr>
<tr class="odd">
<td></td>
<td>break_ties</td>
<td>False</td>
</tr>
<tr class="even">
<td></td>
<td>random_state</td>
<td>None</td>
</tr>
</tbody>
</table>
<p>function copyToClipboard(text, element) { // Get the parameter prefix
from the closest toggleable content const toggleableContent =
element.closest(â€™.sk-toggleable__contentâ€™); const paramPrefix =
toggleableContent ? toggleableContent.dataset.paramPrefix : â€™â€™; const
fullParamName = paramPrefix ? <code>${paramPrefix}${text}</code> :
text;</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">const</span> originalStyle = element.style<span class="kw">;</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="ex">const</span> computedStyle = window.getComputedStyle<span class="er">(</span><span class="ex">element</span><span class="kw">);</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="ex">const</span> originalWidth = computedStyle.width<span class="kw">;</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="ex">const</span> originalHTML = element.innerHTML.replace<span class="er">(</span><span class="st">'Copied!'</span><span class="ex">,</span> <span class="st">''</span><span class="kw">);</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="ex">navigator.clipboard.writeText</span><span class="er">(</span><span class="ex">fullParamName</span><span class="kw">)</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    <span class="ex">.then</span><span class="er">((</span><span class="kw">)</span> <span class="ex">=</span><span class="op">&gt;</span> {</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>        <span class="ex">element.style.width</span> = originalWidth<span class="kw">;</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>        <span class="ex">element.style.color</span> = <span class="st">'green'</span><span class="kw">;</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>        <span class="ex">element.innerHTML</span> = <span class="st">"Copied!"</span><span class="kw">;</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>        <span class="ex">setTimeout</span><span class="er">((</span><span class="kw">)</span> <span class="ex">=</span><span class="op">&gt;</span> {</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>            <span class="ex">element.innerHTML</span> = originalHTML<span class="kw">;</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>            <span class="ex">element.style</span> = originalStyle<span class="kw">;</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>        <span class="er">}</span><span class="ex">,</span> 2000<span class="kw">);</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>    <span class="er">}</span><span class="kw">)</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    <span class="ex">.catch</span><span class="er">(</span><span class="ex">err</span> =<span class="op">&gt;</span> {</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>        <span class="ex">console.error</span><span class="er">(</span><span class="st">'Failed to copy:'</span><span class="ex">,</span> err<span class="kw">);</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>        <span class="ex">element.style.color</span> = <span class="st">'red'</span><span class="kw">;</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>        <span class="ex">element.innerHTML</span> = <span class="st">"Failed!"</span><span class="kw">;</span></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>        <span class="ex">setTimeout</span><span class="er">((</span><span class="kw">)</span> <span class="ex">=</span><span class="op">&gt;</span> {</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>            <span class="ex">element.innerHTML</span> = originalHTML<span class="kw">;</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>            <span class="ex">element.style</span> = originalStyle<span class="kw">;</span></span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>        <span class="er">}</span><span class="ex">,</span> 2000<span class="kw">);</span></span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>    <span class="er">}</span><span class="kw">);</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="cf">return</span> <span class="fu">false</span><span class="kw">;</span></span></code></pre>
</div>
<p>}</p>
<p>document.querySelectorAll(â€˜.fa-regular.fa-copyâ€™).forEach(function(element)
{ const toggleableContent = element.closest(â€™.sk-toggleable__contentâ€™);
const paramPrefix = toggleableContent ?
toggleableContent.dataset.paramPrefix : â€™â€™; const paramName =
element.parentElement.nextElementSibling.textContent.trim(); const
fullParamName = paramPrefix ? <code>${paramPrefix}${paramName}</code> :
paramName;</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">element.setAttribute</span><span class="er">(</span><span class="st">'title'</span><span class="ex">,</span> fullParamName<span class="kw">);</span></span></code></pre>
</div>
<p>});</p>
</div>
<div class="section level2">
<h2 id="step-4-evaluate-the-model">Step 4: Evaluate the Model<a class="anchor" aria-label="anchor" href="#step-4-evaluate-the-model"></a>
</h2>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    accuracy_score, precision_score, recall_score, f1_score,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    ConfusionMatrixDisplay, classification_report, roc_curve, auc</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(y_test, y_pred))</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Precision:"</span>, precision_score(y_test, y_pred))</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Recall:"</span>, recall_score(y_test, y_pred))</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score:"</span>, f1_score(y_test, y_pred))</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred))</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">Accuracy:</span> 0.9766081871345029</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="ex">Precision:</span> 0.972972972972973</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="ex">Recall:</span> 0.9908256880733946</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="ex">F1</span> Score: 0.9818181818181818</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="ex">Classification</span> Report:</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>               <span class="ex">precision</span>    recall  f1-score   support</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>           <span class="ex">0</span>       0.98      0.95      0.97        62</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>           <span class="ex">1</span>       0.97      0.99      0.98       109</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    <span class="ex">accuracy</span>                           0.98       171</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>   <span class="ex">macro</span> avg       0.98      0.97      0.97       171</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="ex">weighted</span> avg       0.98      0.98      0.98       171</span></code></pre>
</div>
<div class="section level3">
<h3 id="what-is-a-confusion-matrix">What is a Confusion Matrix?<a class="anchor" aria-label="anchor" href="#what-is-a-confusion-matrix"></a>
</h3>
<p>A <strong>confusion matrix</strong> is a summary of prediction
results:</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Actual Positive</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr class="even">
<td>Actual Negative</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<ul>
<li>Accuracy, Precision, Recall, F1 Score are all derived from this
table.</li>
</ul>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>plt.title(<span class="st">'SVM Confusion Matrix'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="04_svm/output_9_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level3">
<h3 id="what-is-an-roc-curve">What is an ROC Curve?<a class="anchor" aria-label="anchor" href="#what-is-an-roc-curve"></a>
</h3>
<p>The <strong>ROC Curve</strong> shows the trade-off between True
Positive Rate (Recall) and False Positive Rate. The <strong>AUC (Area
Under Curve)</strong> summarizes the performance into a single
number.</p>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_proba)</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="st">'AUC = '</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">round</span>(roc_auc, <span class="dv">2</span>)))</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>plt.title(<span class="st">'SVM ROC Curve'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="04_svm/output_11_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-05_svm_optimization"><p>Content from <a href="05_svm_optimization.html">05 Svm Optimization</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/05_svm_optimization.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="optimising-a-support-vector-machine-svm-classifier">Optimising a Support Vector Machine (SVM) Classifier<a class="anchor" aria-label="anchor" href="#optimising-a-support-vector-machine-svm-classifier"></a>
</h1>
<p>In this notebook, we demonstrate how to <strong>tune
hyperparameters</strong> in a Support Vector Machine (SVM) classifier to
improve classification performance.</p>
<p>We will use the <strong>Breast Cancer Wisconsin dataset</strong> to:
- Train an initial SVM model. - Explore the effects of the most
important hyperparameters: - <code>C</code> â€” Regularization parameter
controlling the trade-off between achieving low training error and low
testing error. - <code>gamma</code> â€” Kernel coefficient controlling how
much influence each data point has on the decision boundary. -
<code>kernel</code> â€” Defines the type of decision boundary (linear or
nonlinear), with options like <code>'linear'</code>, <code>'rbf'</code>,
and <code>'poly'</code>.</p>
<p>Support Vector Machines are powerful models for classification tasks
and can handle both linear and non-linear relationships through the use
of kernel functions. By tuning these hyperparameters, we can
significantly improve model performance.</p>
<div class="section level2">
<h2 id="step-1-load-breast-cancer-data">Step 1: Load Breast Cancer Data<a class="anchor" aria-label="anchor" href="#step-1-load-breast-cancer-data"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="exploring-the-effect-of-the-c-hyperparameter">Exploring the Effect of the <code>C</code> Hyperparameter<a class="anchor" aria-label="anchor" href="#exploring-the-effect-of-the-c-hyperparameter"></a>
</h2>
<p>The <code>C</code> parameter in SVM controls the
<strong>regularization strength</strong>: - <strong>Low <code>C</code>
values</strong> â†’ More regularization â†’ Smoother decision boundary,
possibly underfitting. - <strong>High <code>C</code> values</strong> â†’
Less regularization â†’ Fits the training data more closely, potentially
overfitting.</p>
<p>We will train SVM models with different <code>C</code> values and
observe how it affects accuracy.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># Test different values of C</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>C_values <span class="op">=</span> [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">100</span>]</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="cf">for</span> C <span class="kw">in</span> C_values:</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    model <span class="op">=</span> SVC(C<span class="op">=</span>C, kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="st">'scale'</span>)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    train_scores.append(train_acc)</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    test_scores.append(test_acc)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>plt.semilogx(C_values, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Accuracy'</span>)</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>plt.semilogx(C_values, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>plt.xlabel(<span class="st">'C (log scale)'</span>)</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>plt.title(<span class="st">'Effect of Regularization Parameter C on SVM'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="05_svm_optimization/output_4_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="exploring-the-effect-of-the-gamma-hyperparameter">Exploring the Effect of the <code>gamma</code> Hyperparameter<a class="anchor" aria-label="anchor" href="#exploring-the-effect-of-the-gamma-hyperparameter"></a>
</h2>
<p>The <code>gamma</code> parameter controls the <strong>influence of
each individual training example</strong>: - <strong>Low
<code>gamma</code> values</strong> â†’ Far-reaching influence â†’ Smoother
decision boundary, possibly underfitting. - <strong>High
<code>gamma</code> values</strong> â†’ Very localized influence â†’ Complex
decision boundary, potentially overfitting.</p>
<p>We will now examine how varying <code>gamma</code> affects the
modelâ€™s performance, while keeping <code>C</code> fixed.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Test different values of gamma</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>gamma_values <span class="op">=</span> [<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">10</span>]</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="cf">for</span> gamma <span class="kw">in</span> gamma_values:</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    model <span class="op">=</span> SVC(C<span class="op">=</span><span class="dv">1</span>, kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span>gamma)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    train_scores.append(train_acc)</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    test_scores.append(test_acc)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>plt.semilogx(gamma_values, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Accuracy'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>plt.semilogx(gamma_values, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>plt.xlabel(<span class="st">'gamma (log scale)'</span>)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>plt.title(<span class="st">'Effect of gamma on SVM'</span>)</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="05_svm_optimization/output_6_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="exploring-the-effect-of-the-kernel-hyperparameter">Exploring the Effect of the <code>kernel</code> Hyperparameter<a class="anchor" aria-label="anchor" href="#exploring-the-effect-of-the-kernel-hyperparameter"></a>
</h2>
<p>The <code>kernel</code> parameter in SVM specifies the <strong>type
of transformation</strong> applied to the input data: -
<code>'linear'</code> â†’ No transformation; linear decision boundary. -
<code>'rbf'</code> (Radial Basis Function) â†’ Maps data into higher
dimensions for non-linear boundaries. - <code>'poly'</code> â†’ Polynomial
transformations, allowing more flexible decision boundaries depending on
degree.</p>
<p>We will now compare different kern</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Test different kernel types</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>kernel_types <span class="op">=</span> [<span class="st">'linear'</span>, <span class="st">'rbf'</span>, <span class="st">'poly'</span>]</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="cf">for</span> kernel <span class="kw">in</span> kernel_types:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    model <span class="op">=</span> SVC(C<span class="op">=</span><span class="dv">1</span>, kernel<span class="op">=</span>kernel, gamma<span class="op">=</span><span class="st">'scale'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    train_scores.append(train_acc)</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    test_scores.append(test_acc)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co"># Show numeric results</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="cf">for</span> k, tr, te <span class="kw">in</span> <span class="bu">zip</span>(kernel_types, train_scores, test_scores):</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Kernel: </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss"> â†’ Train Accuracy: </span><span class="sc">{</span>tr<span class="sc">:.3f}</span><span class="ss">, Test Accuracy: </span><span class="sc">{</span>te<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="bu">len</span>(kernel_types))</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>plt.bar(x <span class="op">-</span> width<span class="op">/</span><span class="dv">2</span>, train_scores, width, label<span class="op">=</span><span class="st">'Train Accuracy'</span>)</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>plt.bar(x <span class="op">+</span> width<span class="op">/</span><span class="dv">2</span>, test_scores, width, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>plt.xticks(x, kernel_types)</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>plt.xlabel(<span class="st">'Kernel Type'</span>)</span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>plt.title(<span class="st">'Comparison of SVM Kernels'</span>)</span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a>plt.grid(<span class="va">True</span>, axis<span class="op">=</span><span class="st">'y'</span>)</span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">Kernel:</span> linear â†’ Train Accuracy: 0.987, Test Accuracy: 0.988</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="ex">Kernel:</span> rbf â†’ Train Accuracy: 0.985, Test Accuracy: 0.977</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="ex">Kernel:</span> poly â†’ Train Accuracy: 0.910, Test Accuracy: 0.883</span></code></pre>
</div>
<figure><img src="05_svm_optimization/output_8_1.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="changing-the-classification-threshold">Changing the Classification Threshold<a class="anchor" aria-label="anchor" href="#changing-the-classification-threshold"></a>
</h2>
<p>Most classifiers output probabilities between 0 and 1. By default,
the threshold for classification is 0.5. This means:</p>
<ul>
<li>If predicted probability â‰¥ 0.5 â†’ classify as
<strong>positive</strong>
</li>
<li>Else â†’ classify as <strong>negative</strong>
</li>
</ul>
<div class="section level3">
<h3 id="changing-the-threshold">Changing the Threshold:<a class="anchor" aria-label="anchor" href="#changing-the-threshold"></a>
</h3>
<ul>
<li>
<strong>Lower threshold</strong> â†’ more positives predicted â†’ higher
<strong>recall</strong>, more <strong>false positives</strong>
</li>
<li>
<strong>Higher threshold</strong> â†’ fewer positives predicted â†’
higher <strong>precision</strong>, more <strong>false
negatives</strong>
</li>
</ul>
<p>Choosing the right threshold depends on your applicationâ€™s goals.</p>
<p>Weâ€™ll now visualize how the confusion matrix changes for <strong>two
different thresholds</strong>.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>thresholds <span class="op">=</span> [<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>]         <span class="co"># List of two thresholds to compare</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># Train SVM with probability estimates enabled</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>model <span class="op">=</span> SVC(C<span class="op">=</span><span class="dv">1</span>, kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="st">'scale'</span>, probability<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co"># Predict probabilities</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability of class 1</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co"># Plot side-by-side confusion matrices</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="cf">for</span> i, thresh <span class="kw">in</span> <span class="bu">enumerate</span>(thresholds):</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>    y_pred <span class="op">=</span> (y_proba <span class="op">&amp;</span>gt<span class="op">;=</span> thresh).astype(<span class="bu">int</span>)</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax<span class="op">=</span>axs[i])</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>    axs[i].set_title(<span class="ss">f"Threshold = </span><span class="sc">{</span>thresh<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="05_svm_optimization/output_10_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-06_model_evaluation"><p>Content from <a href="06_model_evaluation.html">06 Model Evaluation</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/06_model_evaluation.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="model-evaluation-comparing-logistic-regression-and-svm">Model Evaluation: Comparing Logistic Regression and SVM<a class="anchor" aria-label="anchor" href="#model-evaluation-comparing-logistic-regression-and-svm"></a>
</h1>
<p>We compare two classifiers: - <strong>Logistic Regression</strong> -
<strong>SVM</strong></p>
<p>Using metrics: Accuracy, Precision, Recall, F1 Score, Confusion
Matrix, and ROC-AUC.</p>
<div class="section level2">
<h2 id="step-1-load-the-data">Step 1: Load the Data<a class="anchor" aria-label="anchor" href="#step-1-load-the-data"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-2-train-the-models">Step 2: Train the Models<a class="anchor" aria-label="anchor" href="#step-2-train-the-models"></a>
</h2>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>lr_model <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">5000</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>lr_model.fit(X_train, y_train)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>svm_model <span class="op">=</span> SVC(probability<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>svm_model.fit(X_train, y_train)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-evaluation-metrics">Step 3: Evaluation Metrics<a class="anchor" aria-label="anchor" href="#step-3-evaluation-metrics"></a>
</h2>
<div class="section level3">
<h3 id="what-is-accuracy">What is Accuracy?<a class="anchor" aria-label="anchor" href="#what-is-accuracy"></a>
</h3>
<p><strong>Accuracy</strong> is the proportion of correct
predictions:</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]</span></p>
<p>Can be misleading if classes are imbalanced.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>lr_acc <span class="op">=</span> accuracy_score(y_test, lr_model.predict(X_test))</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>svm_acc <span class="op">=</span> accuracy_score(y_test, svm_model.predict(X_test))</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Logistic egression Accuracy: </span><span class="sc">{</span>lr_acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"SVM Accuracy: </span><span class="sc">{</span>svm_acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">Logistic</span> egression Accuracy: 0.98</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="ex">SVM</span> Accuracy: 0.98</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="what-are-precision-recall-and-f1-score">What are Precision, Recall and F1 Score?<a class="anchor" aria-label="anchor" href="#what-are-precision-recall-and-f1-score"></a>
</h3>
<ul>
<li>
<strong>Precision</strong>: <span class="math inline">\(\frac{TP}{TP
+ FP}\)</span><br>
</li>
<li>
<strong>Recall</strong>: <span class="math inline">\(\frac{TP}{TP +
FN}\)</span><br>
</li>
<li>
<strong>F1 Score</strong>: Harmonic mean of precision and
recall</li>
</ul>
<p><span class="math display">\[
F1 = 2 \cdot \frac{\text{Precision} \cdot
\text{Recall}}{\text{Precision} + \text{Recall}}
\]</span></p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score, f1_score</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> [(<span class="st">"SVM"</span>, svm_model), (<span class="st">"Neural Net"</span>, lr_model)]:</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> Metrics:"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Recall: </span><span class="sc">{</span>recall_score(y_test, y_pred)<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"F1 Score: </span><span class="sc">{</span>f1_score(y_test, y_pred)<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="ex">SVM</span> Metrics:</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="ex">Precision:</span> 0.97</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="ex">Recall:</span> 0.99</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="ex">F1</span> Score: 0.98</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="ex">Neural</span> Net Metrics:</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="ex">Precision:</span> 0.98</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="ex">Recall:</span> 0.98</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="ex">F1</span> Score: 0.98</span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="what-is-a-confusion-matrix">What is a Confusion Matrix?<a class="anchor" aria-label="anchor" href="#what-is-a-confusion-matrix"></a>
</h3>
<p>A <strong>confusion matrix</strong> shows the breakdown of correct
and incorrect classifications.</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Actual Positive</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr class="even">
<td>Actual Negative</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(svm_model, X_test, y_test, ax<span class="op">=</span>axs[<span class="dv">0</span>])</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">"SVM Confusion Matrix"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(lr_model, X_test, y_test, ax<span class="op">=</span>axs[<span class="dv">1</span>])</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">"Neural Network Confusion Matrix"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="06_model_evaluation/output_11_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level3">
<h3 id="what-is-the-roc-curve">What is the ROC Curve?<a class="anchor" aria-label="anchor" href="#what-is-the-roc-curve"></a>
</h3>
<p>ROC = Receiver Operating Characteristic Curve</p>
<ul>
<li>Plots TPR vs FPR</li>
<li>
<strong>AUC</strong> = Area Under the ROC Curve Closer to 1 = better
model.</li>
</ul>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>svm_probs <span class="op">=</span> svm_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>nn_probs <span class="op">=</span> lr_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>svm_fpr, svm_tpr, _ <span class="op">=</span> roc_curve(y_test, svm_probs)</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>nn_fpr, nn_tpr, _ <span class="op">=</span> roc_curve(y_test, nn_probs)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>svm_auc <span class="op">=</span> auc(svm_fpr, svm_tpr)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>nn_auc <span class="op">=</span> auc(nn_fpr, nn_tpr)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>plt.plot(svm_fpr, svm_tpr, label<span class="op">=</span><span class="ss">f"SVM (AUC = </span><span class="sc">{</span>svm_auc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>plt.plot(nn_fpr, nn_tpr, label<span class="op">=</span><span class="ss">f"Logistic Regression (AUC = </span><span class="sc">{</span>nn_auc<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>)</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve"</span>)</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>plt.legend()</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="06_model_evaluation/output_13_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>Both models perform well, but:</p>
<ul>
<li>
<strong>Neural Net</strong> may achieve higher recall</li>
<li>
<strong>SVM</strong> may offer higher precision</li>
</ul>
<p>Evaluation metrics guide us to choose the best model for our
real-world use case.</p>
<!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div></section><section id="aio-07_neural_networks"><p>Content from <a href="07_neural_networks.html">07 Neural Networks</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/07_neural_networks.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="neural-network-mlpclassifier-with-breast-cancer-dataset">Neural Network (MLPClassifier) with Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#neural-network-mlpclassifier-with-breast-cancer-dataset"></a>
</h1>
<p>In this notebook, we will use a simple <strong>Multi-layer Perceptron
(MLP)</strong> neural network to classify breast tumors.</p>
<div class="section level2">
<h2 id="what-is-an-mlp">What is an MLP?<a class="anchor" aria-label="anchor" href="#what-is-an-mlp"></a>
</h2>
<p>An <strong>MLP</strong> is a type of <strong>feedforward neural
network</strong> consisting of one or more hidden layers. Each neuron
computes a weighted sum of its inputs and passes the result through a
nonlinear activation function.</p>
<p>MLPs are suitable for classification tasks and are trained using
<strong>backpropagation</strong> to minimize loss.</p>
</div>
<div class="section level2">
<h2 id="step-1-load-the-breast-cancer-dataset">Step 1: Load the Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#step-1-load-the-breast-cancer-dataset"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-train-an-mlpclassifier">Step 3: Train an MLPClassifier<a class="anchor" aria-label="anchor" href="#step-3-train-an-mlpclassifier"></a>
</h2>
<p>We use <code>MLPClassifier</code> from Scikit-Learn with one hidden
layer.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>model <span class="op">=</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>(<span class="dv">50</span>,), max_iter<span class="op">=</span><span class="dv">2000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>model.fit(X_train, y_train)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-4-evaluate-the-model">Step 4: Evaluate the Model<a class="anchor" aria-label="anchor" href="#step-4-evaluate-the-model"></a>
</h2>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    accuracy_score, precision_score, recall_score, f1_score,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    ConfusionMatrixDisplay, classification_report, roc_curve, auc</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(y_test, y_pred))</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Precision:"</span>, precision_score(y_test, y_pred))</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Recall:"</span>, recall_score(y_test, y_pred))</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score:"</span>, f1_score(y_test, y_pred))</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred))</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">Accuracy:</span> 0.9824561403508771</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="ex">Precision:</span> 0.9732142857142857</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="ex">Recall:</span> 1.0</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="ex">F1</span> Score: 0.9864253393665159</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="ex">Classification</span> Report:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>               <span class="ex">precision</span>    recall  f1-score   support</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>           <span class="ex">0</span>       1.00      0.95      0.98        62</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>           <span class="ex">1</span>       0.97      1.00      0.99       109</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    <span class="ex">accuracy</span>                           0.98       171</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>   <span class="ex">macro</span> avg       0.99      0.98      0.98       171</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="ex">weighted</span> avg       0.98      0.98      0.98       171</span></code></pre>
</div>
<div class="section level3">
<h3 id="what-is-a-confusion-matrix">What is a Confusion Matrix?<a class="anchor" aria-label="anchor" href="#what-is-a-confusion-matrix"></a>
</h3>
<p>A <strong>confusion matrix</strong> shows how well the model
distinguishes between classes:</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Actual Positive</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr class="even">
<td>Actual Negative</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<p>This matrix lets us compute metrics like accuracy, precision, recall,
and F1 score.</p>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>plt.title(<span class="st">'Neural Network Confusion Matrix'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="07_neural_networks/output_9_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level3">
<h3 id="what-is-an-roc-curve">What is an ROC Curve?<a class="anchor" aria-label="anchor" href="#what-is-an-roc-curve"></a>
</h3>
<p>The <strong>ROC Curve</strong> shows the trade-off between True
Positive Rate and False Positive Rate. <strong>AUC</strong> quantifies
this performance. Closer to 1.0 = better classifier.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_proba)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="st">'AUC = '</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">round</span>(roc_auc, <span class="dv">2</span>)))</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>plt.title(<span class="st">'Neural Network ROC Curve'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="07_neural_networks/output_11_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-08_neural_networks_optimization"><p>Content from <a href="08_neural_networks_optimization.html">08 Neural Networks Optimization</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/08_neural_networks_optimization.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="optimising-a-neural-network-classifier">Optimising a Neural Network Classifier<a class="anchor" aria-label="anchor" href="#optimising-a-neural-network-classifier"></a>
</h1>
<p>In this notebook, we demonstrate how to <strong>tune
hyperparameters</strong> in a neural network model to improve
performance.</p>
<p>We will focus on: - <code>hidden_layer_sizes</code> -
<code>alpha</code> (regularization) -
<code>learning_rate_init</code></p>
<p>Weâ€™ll also visualize how these parameters affect accuracy, and look
for signs of overfitting or underfitting.</p>
<div class="section level2">
<h2 id="step-1-load-breast-cancer-data">Step 1: Load Breast Cancer Data<a class="anchor" aria-label="anchor" href="#step-1-load-breast-cancer-data"></a>
</h2>
<p>Load with Normalisation</p>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># from sklearn.datasets import load_breast_cancer</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="co"># from sklearn.model_selection import train_test_split</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="co"># from sklearn.preprocessing import StandardScaler</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co"># import pandas as pd</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># # Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># data = load_breast_cancer()</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co"># X = data.data</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co"># y = data.target</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># # Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co"># X_train, X_test, y_train, y_test = train_test_split(</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co">#     X, y, test_size=0.3, random_state=31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># # Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a><span class="co"># scaler = StandardScaler()</span></span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a><span class="co"># X_train = scaler.fit_transform(X_train)</span></span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a><span class="co"># X_test = scaler.transform(X_test)</span></span></code></pre>
</div>
<p>Load without Normalisation To see the effects of different network
sizes and other hyperparameters we use the non-normlaised dataset. For
teh easier task of calssifying using normalised data most values for
hyperparameters result in a very good accuracy.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-2-define-a-function-to-train-and-evaluate">Step 2: Define a Function to Train and Evaluate<a class="anchor" aria-label="anchor" href="#step-2-define-a-function-to-train-and-evaluate"></a>
</h2>
<p>This function will: - Train the MLP model - Return training and test
accuracy</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="kw">def</span> train_and_evaluate(hidden_layer_sizes<span class="op">=</span>(<span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">400</span>, <span class="dv">200</span>), alpha<span class="op">=</span><span class="fl">0.0001</span>, lr<span class="op">=</span><span class="fl">0.001</span>):</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    model <span class="op">=</span> MLPClassifier(hidden_layer_sizes<span class="op">=</span>hidden_layer_sizes,</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>                           alpha<span class="op">=</span>alpha,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>                           learning_rate_init<span class="op">=</span>lr,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>                           max_iter<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>                           random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>    <span class="cf">return</span> train_acc, test_acc</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-explore-effect-of-hidden_layer_sizes">Step 3: Explore Effect of <code>hidden_layer_sizes</code>
<a class="anchor" aria-label="anchor" href="#step-3-explore-effect-of-hidden_layer_sizes"></a>
</h2>
<p>The number of neurons and layers controls the modelâ€™s capacity.</p>
<ul>
<li>Too small: underfitting</li>
<li>Too large: overfitting</li>
</ul>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>values <span class="op">=</span> [ (<span class="dv">50</span>,<span class="dv">50</span>), (<span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">50</span>), (<span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">400</span>, <span class="dv">200</span>), (<span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">400</span>, <span class="dv">400</span>, <span class="dv">400</span>, <span class="dv">200</span>), (<span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">800</span>, <span class="dv">800</span>, <span class="dv">800</span>, <span class="dv">400</span>, <span class="dv">400</span>, <span class="dv">200</span>)]</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>labels <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>train_scores, test_scores <span class="op">=</span> [], []</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="cf">for</span> s <span class="kw">in</span> values:</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    tr, te <span class="op">=</span> train_and_evaluate(hidden_layer_sizes<span class="op">=</span>s)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    train_scores.append(tr)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    test_scores.append(te)</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>labels <span class="op">=</span> [<span class="bu">str</span>(s) <span class="cf">for</span> s <span class="kw">in</span> values]</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>plt.plot(labels, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Acc'</span>)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>plt.plot(labels, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Acc'</span>)</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>plt.xlabel(<span class="st">'Hidden Layer Sizes'</span>)</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>plt.title(<span class="st">'Effect of Network Size'</span>)</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="08_neural_networks_optimization/output_9_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="step-4-explore-effect-of-alpha-l2-regularization">Step 4: Explore Effect of <code>alpha</code> (L2
Regularization)<a class="anchor" aria-label="anchor" href="#step-4-explore-effect-of-alpha-l2-regularization"></a>
</h2>
<p><code>alpha</code> prevents overfitting by penalising large
weights.</p>
<ul>
<li>Low <code>alpha</code>: can overfit</li>
<li>High <code>alpha</code>: can underfit</li>
</ul>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>alphas <span class="op">=</span>  [<span class="fl">1e-1</span>, <span class="fl">3e-1</span>, <span class="fl">5e-1</span>, <span class="fl">7e-1</span>, <span class="fl">1e1</span>]</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>train_scores, test_scores <span class="op">=</span> [], []</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="cf">for</span> a <span class="kw">in</span> alphas:</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    tr, te <span class="op">=</span> train_and_evaluate(alpha<span class="op">=</span>a)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    train_scores.append(tr)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    test_scores.append(te)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>plt.semilogx(alphas, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Acc'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>plt.semilogx(alphas, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Acc'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>plt.xlabel(<span class="st">'alpha (log scale)'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>plt.title(<span class="st">'Effect of Regularization Strength'</span>)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="08_neural_networks_optimization/output_11_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="step-5-explore-effect-of-learning_rate_init">Step 5: Explore Effect of <code>learning_rate_init</code>
<a class="anchor" aria-label="anchor" href="#step-5-explore-effect-of-learning_rate_init"></a>
</h2>
<p>This controls how fast the model updates its weights.</p>
<ul>
<li>Too small: slow convergence</li>
<li>Too large: may never converge</li>
</ul>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>lrs <span class="op">=</span> [<span class="fl">1e-5</span>, <span class="fl">1e-4</span>, <span class="fl">1e-3</span>, <span class="fl">1e-2</span>, <span class="fl">1e-1</span>]</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>train_scores, test_scores <span class="op">=</span> [], []</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="cf">for</span> lr <span class="kw">in</span> lrs:</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    tr, te <span class="op">=</span> train_and_evaluate(lr<span class="op">=</span>lr)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    train_scores.append(tr)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>    test_scores.append(te)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>plt.plot(lrs, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Acc'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>plt.plot(lrs, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Acc'</span>)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>plt.xscale(<span class="st">'log'</span>)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>plt.xlabel(<span class="st">'Learning Rate (log scale)'</span>)</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>plt.title(<span class="st">'Effect of Learning Rate'</span>)</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="08_neural_networks_optimization/output_13_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<ul>
<li>Neural networks are sensitive to hyperparameters</li>
<li>Use visualisation to find sweet spot</li>
<li>Avoid overfitting by tuning <code>alpha</code> and
<code>hidden_layer_sizes</code>
</li>
<li>Donâ€™t pick hyperparameters blindly â€“ use grid search or
cross-validation</li>
</ul>
<hr>
</div>
<div class="section level2">
<h2 id="changing-the-classification-threshold">Changing the Classification Threshold<a class="anchor" aria-label="anchor" href="#changing-the-classification-threshold"></a>
</h2>
<p>Most classifiers like neural networks output probabilities between 0
and 1. By default, the threshold for classification is 0.5. This
means:</p>
<ul>
<li>If predicted probability â‰¥ 0.5 â†’ classify as
<strong>positive</strong>
</li>
<li>Else â†’ classify as <strong>negative</strong>
</li>
</ul>
<div class="section level3">
<h3 id="changing-the-threshold">Changing the Threshold:<a class="anchor" aria-label="anchor" href="#changing-the-threshold"></a>
</h3>
<ul>
<li>
<strong>Lower threshold</strong> â†’ more positives predicted â†’ higher
<strong>recall</strong>, more <strong>false positives</strong>
</li>
<li>
<strong>Higher threshold</strong> â†’ fewer positives predicted â†’
higher <strong>precision</strong>, more <strong>false
negatives</strong>
</li>
</ul>
<p>Choosing the right threshold depends on your applicationâ€™s goals.</p>
<p>Weâ€™ll now visualize how the confusion matrix changes for <strong>two
different thresholds</strong>.</p>
<div class="codewrapper sourceCode" id="cb7">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>thresholds <span class="op">=</span> [<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>]         <span class="co"># List of two thresholds to compare</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co"># Retrain model</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>manual_model <span class="op">=</span> MLPClassifier()</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>manual_model.fit(X_train, y_train)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co"># Predict probabilities</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>y_proba <span class="op">=</span> manual_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co"># Plot side-by-side confusion matrices</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="cf">for</span> i, thresh <span class="kw">in</span> <span class="bu">enumerate</span>(thresholds):</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    y_pred <span class="op">=</span> (y_proba <span class="op">&amp;</span>gt<span class="op">;=</span> thresh).astype(<span class="bu">int</span>)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax<span class="op">=</span>axs[i])</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    axs[i].set_title(<span class="ss">f"Threshold = </span><span class="sc">{</span>thresh<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb8">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="ex">C:\Users\moji1\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sklearn\neural_network\_multilayer_perceptron.py:780:</span> ConvergenceWarning: Stochastic Optimizer: Maximum iterations <span class="er">(</span><span class="ex">200</span><span class="kw">)</span> <span class="ex">reached</span> and the optimization hasn<span class="st">'t converged yet.</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="st">  warnings.warn(</span></span></code></pre>
</div>
<figure><img src="08_neural_networks_optimization/output_16_1.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-09_random_forest"><p>Content from <a href="09_random_forest.html">09 Random Forest</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/09_random_forest.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="random-forest-classifier-with-breast-cancer-dataset">Random Forest Classifier with Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#random-forest-classifier-with-breast-cancer-dataset"></a>
</h1>
<p>This notebook demonstrates the use of <strong>Random Forest
Classifier</strong> for classifying tumors in the Breast Cancer
dataset.</p>
<div class="section level2">
<h2 id="what-is-a-random-forest">What is a Random Forest?<a class="anchor" aria-label="anchor" href="#what-is-a-random-forest"></a>
</h2>
<p>Random Forest is a powerful ensemble learning method for
classification. It builds multiple <strong>decision trees</strong> and
combines their predictions for improved accuracy and robustness.</p>
<p>Each tree is trained on a random subset of the data and features,
reducing overfitting and improving generalization.</p>
</div>
<div class="section level2">
<h2 id="step-1-load-the-breast-cancer-dataset">Step 1: Load the Breast Cancer Dataset<a class="anchor" aria-label="anchor" href="#step-1-load-the-breast-cancer-dataset"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-3-train-an-svm-model">Step 3: Train an SVM Model<a class="anchor" aria-label="anchor" href="#step-3-train-an-svm-model"></a>
</h2>
<p>We use the <code>SVC</code> class from <code>sklearn.svm</code> with
default kernel (RBF).</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>model <span class="op">=</span> RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>model.fit(X_train, y_train)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="step-4-evaluate-the-model">Step 4: Evaluate the Model<a class="anchor" aria-label="anchor" href="#step-4-evaluate-the-model"></a>
</h2>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    accuracy_score, precision_score, recall_score, f1_score,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    ConfusionMatrixDisplay, classification_report, roc_curve, auc</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Accuracy:"</span>, accuracy_score(y_test, y_pred))</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Precision:"</span>, precision_score(y_test, y_pred))</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Recall:"</span>, recall_score(y_test, y_pred))</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"F1 Score:"</span>, f1_score(y_test, y_pred))</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Classification Report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred))</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="ex">Accuracy:</span> 0.9590643274853801</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="ex">Precision:</span> 0.9636363636363636</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="ex">Recall:</span> 0.9724770642201835</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="ex">F1</span> Score: 0.9680365296803652</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="ex">Classification</span> Report:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>               <span class="ex">precision</span>    recall  f1-score   support</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>           <span class="ex">0</span>       0.95      0.94      0.94        62</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>           <span class="ex">1</span>       0.96      0.97      0.97       109</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    <span class="ex">accuracy</span>                           0.96       171</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>   <span class="ex">macro</span> avg       0.96      0.95      0.96       171</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="ex">weighted</span> avg       0.96      0.96      0.96       171</span></code></pre>
</div>
<div class="section level3">
<h3 id="what-is-a-confusion-matrix">What is a Confusion Matrix?<a class="anchor" aria-label="anchor" href="#what-is-a-confusion-matrix"></a>
</h3>
<p>A <strong>confusion matrix</strong> is a summary of prediction
results:</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Actual Positive</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr class="even">
<td>Actual Negative</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<ul>
<li>Accuracy, Precision, Recall, F1 Score are all derived from this
table.</li>
</ul>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>plt.title(<span class="st">'SVM Confusion Matrix'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="09_random_forest/output_9_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level3">
<h3 id="what-is-an-roc-curve">What is an ROC Curve?<a class="anchor" aria-label="anchor" href="#what-is-an-roc-curve"></a>
</h3>
<p>The <strong>ROC Curve</strong> shows the trade-off between True
Positive Rate (Recall) and False Positive Rate. The <strong>AUC (Area
Under Curve)</strong> summarizes the performance into a single
number.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>fpr, tpr, _ <span class="op">=</span> roc_curve(y_test, y_proba)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="st">'AUC = '</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">round</span>(roc_auc, <span class="dv">2</span>)))</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">'k--'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>plt.xlabel(<span class="st">'False Positive Rate'</span>)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>plt.ylabel(<span class="st">'True Positive Rate'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>plt.title(<span class="st">'SVM ROC Curve'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>plt.legend()</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="09_random_forest/output_11_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section><section id="aio-10_random_forest_optimization"><p>Content from <a href="10_random_forest_optimization.html">10 Random Forest Optimization</a></p>
<hr>
<p>Last updated on 2025-07-10 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/10_random_forest_optimization.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="section level1">
<h1 id="optimising-a-random-forest-classifier">Optimising a Random Forest Classifier<a class="anchor" aria-label="anchor" href="#optimising-a-random-forest-classifier"></a>
</h1>
<p>In this notebook, we demonstrate how to <strong>tune
hyperparameters</strong> in a Random Forest Classifier to improve
classification performance.</p>
<p>We will use the <strong>Breast Cancer Wisconsin dataset</strong> to:
- Train an initial Random Forest model. - Explore the effects of the
most important hyperparameters: - <code>n_estimators</code> â€” Number of
trees in the forest. - <code>max_depth</code> â€” Maximum depth of each
tree. - <code>min_samples_split</code> â€” Minimum number of samples
required to split an internal node.</p>
<p>Random Forest is a powerful ensemble method for classification tasks
that builds multiple decision trees and merges their outputs for
improved accuracy and robustness. By tuning these hyperparameters, we
can significantly improve model performance.</p>
<div class="section level2">
<h2 id="step-1-load-breast-cancer-data">Step 1: Load Breast Cancer Data<a class="anchor" aria-label="anchor" href="#step-1-load-breast-cancer-data"></a>
</h2>
<div class="codewrapper sourceCode" id="cb1">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># Split dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">31</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a><span class="co"># Normalize (Standardize) features</span></span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="exploring-the-effect-of-the-n_estimators-hyperparameter">Exploring the Effect of the <code>n_estimators</code>
Hyperparameter<a class="anchor" aria-label="anchor" href="#exploring-the-effect-of-the-n_estimators-hyperparameter"></a>
</h2>
<p>The <code>n_estimators</code> parameter in Random Forest controls the
<strong>number of trees</strong> in the forest: - <strong>Low
<code>n_estimators</code> values</strong> â†’ Fewer trees â†’ Faster
training but possibly underfitting. - <strong>High
<code>n_estimators</code> values</strong> â†’ More trees â†’ Better
performance but increased computation.</p>
<p>We will train Random Forest models with different
<code>n_estimators</code> values and observe how it affects
accuracy.</p>
<div class="codewrapper sourceCode" id="cb2">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># Test different values of n_estimators</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>n_estimators_values <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span> ,<span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">50</span>, <span class="dv">70</span>, <span class="dv">90</span>]</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> n_estimators_values:</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span>n, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    train_scores.append(train_acc)</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    test_scores.append(test_acc)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>plt.plot(n_estimators_values, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Accuracy'</span>)</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>plt.plot(n_estimators_values, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>plt.xlabel(<span class="st">'n_estimators (Number of Trees)'</span>)</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>plt.title(<span class="st">'Effect of n_estimators on Random Forest'</span>)</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="10_random_forest_optimization/output_4_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="exploring-the-effect-of-the-max_depth-hyperparameter">Exploring the Effect of the <code>max_depth</code>
Hyperparameter<a class="anchor" aria-label="anchor" href="#exploring-the-effect-of-the-max_depth-hyperparameter"></a>
</h2>
<p>The <code>max_depth</code> parameter controls the <strong>maximum
depth of each tree</strong>: - <strong>Low <code>max_depth</code>
values</strong> â†’ Shallow trees â†’ Simpler models, possibly underfitting.
- <strong>High <code>max_depth</code> values</strong> â†’ Deeper trees â†’
More complex models, potentially overfitting.</p>
<p>We will now examine how varying <code>max_depth</code> affects the
modelâ€™s performance, while keeping <code>n_estimators</code> fixed.</p>
<div class="codewrapper sourceCode" id="cb3">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Test different values of max_depth</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>max_depth_values <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">20</span>]</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="cf">for</span> depth <span class="kw">in</span> max_depth_values:</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span>depth, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    train_scores.append(train_acc)</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    test_scores.append(test_acc)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>plt.plot(max_depth_values, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Accuracy'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>plt.plot(max_depth_values, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>plt.xlabel(<span class="st">'max_depth'</span>)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>plt.title(<span class="st">'Effect of max_depth on Random Forest'</span>)</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="10_random_forest_optimization/output_6_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="exploring-the-effect-of-the-min_samples_split-hyperparameter">Exploring the Effect of the <code>min_samples_split</code>
Hyperparameter<a class="anchor" aria-label="anchor" href="#exploring-the-effect-of-the-min_samples_split-hyperparameter"></a>
</h2>
<p>The <code>min_samples_split</code> parameter controls the
<strong>minimum number of samples required to split an internal
node</strong>: - <strong>Low <code>min_samples_split</code>
values</strong> â†’ More splits â†’ Complex trees, potentially overfitting.
- <strong>High <code>min_samples_split</code> values</strong> â†’ Fewer
splits â†’ Simpler trees, possibly underfitting.</p>
<p>We will now compare different <code>min_samples_split</code> values
to observe their impact on performance.</p>
<div class="codewrapper sourceCode" id="cb4">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Test different values of min_samples_split</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>min_samples_split_values <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>]</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>train_scores <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>test_scores <span class="op">=</span> []</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="cf">for</span> min_split <span class="kw">in</span> min_samples_split_values:</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">6</span>, min_samples_split<span class="op">=</span>min_split, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    model.fit(X_train, y_train)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    train_acc <span class="op">=</span> accuracy_score(y_train, model.predict(X_train))</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    test_acc <span class="op">=</span> accuracy_score(y_test, model.predict(X_test))</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    train_scores.append(train_acc)</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    test_scores.append(test_acc)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co"># Show numeric results</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a><span class="cf">for</span> m, tr, te <span class="kw">in</span> <span class="bu">zip</span>(min_samples_split_values, train_scores, test_scores):</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"min_samples_split: </span><span class="sc">{</span>m<span class="sc">}</span><span class="ss"> â†’ Train Accuracy: </span><span class="sc">{</span>tr<span class="sc">:.3f}</span><span class="ss">, Test Accuracy: </span><span class="sc">{</span>te<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="bu">len</span>(min_samples_split_values))</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.35</span></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a><span class="co"># plt.figure(figsize=(8, 6))</span></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a><span class="co"># plt.bar(x - width/2, train_scores, width, label='Train Accuracy')</span></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a><span class="co"># plt.bar(x + width/2, test_scores, width, label='Test Accuracy')</span></span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a><span class="co"># plt.xticks(x, min_samples_split_values)</span></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a><span class="co"># plt.xlabel('min_samples_split')</span></span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a><span class="co"># plt.ylabel('Accuracy')</span></span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a><span class="co"># plt.title('Effect of min_samples_split on Random Forest')</span></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a><span class="co"># plt.legend()</span></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a><span class="co"># plt.grid(True, axis='y')</span></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a><span class="co"># plt.show()</span></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a>plt.plot( min_samples_split_values, train_scores, marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'Train Accuracy'</span>)</span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>plt.plot( min_samples_split_values, test_scores, marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a>plt.xlabel(<span class="st">'max_depth'</span>)</span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a>plt.title(<span class="st">'Effect of max_depth on Random Forest'</span>)</span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<div class="codewrapper sourceCode" id="cb5">
<h3 class="code-label">SH<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode sh" tabindex="0"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="ex">min_samples_split:</span> 2 â†’ Train Accuracy: 0.997, Test Accuracy: 0.965</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="ex">min_samples_split:</span> 5 â†’ Train Accuracy: 0.995, Test Accuracy: 0.959</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="ex">min_samples_split:</span> 10 â†’ Train Accuracy: 0.980, Test Accuracy: 0.947</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="ex">min_samples_split:</span> 20 â†’ Train Accuracy: 0.972, Test Accuracy: 0.947</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="ex">min_samples_split:</span> 50 â†’ Train Accuracy: 0.972, Test Accuracy: 0.942</span></code></pre>
</div>
<figure><img src="10_random_forest_optimization/output_8_1.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure>
</div>
<div class="section level2">
<h2 id="changing-the-classification-threshold">Changing the Classification Threshold<a class="anchor" aria-label="anchor" href="#changing-the-classification-threshold"></a>
</h2>
<p>Most classifiers output probabilities between 0 and 1. By default,
the threshold for classification is 0.5. This means:</p>
<ul>
<li>If predicted probability â‰¥ 0.5 â†’ classify as
<strong>positive</strong>
</li>
<li>Else â†’ classify as <strong>negative</strong>
</li>
</ul>
<div class="section level3">
<h3 id="changing-the-threshold">Changing the Threshold:<a class="anchor" aria-label="anchor" href="#changing-the-threshold"></a>
</h3>
<ul>
<li>
<strong>Lower threshold</strong> â†’ more positives predicted â†’ higher
<strong>recall</strong>, more <strong>false positives</strong>
</li>
<li>
<strong>Higher threshold</strong> â†’ fewer positives predicted â†’
higher <strong>precision</strong>, more <strong>false
negatives</strong>
</li>
</ul>
<p>Choosing the right threshold depends on your applicationâ€™s goals.</p>
<p>Weâ€™ll now visualize how the confusion matrix changes for <strong>two
different thresholds</strong>.</p>
<div class="codewrapper sourceCode" id="cb6">
<h3 class="code-label">PYTHON<i aria-hidden="true" data-feather="chevron-left"></i><i aria-hidden="true" data-feather="chevron-right"></i>
</h3>
<pre class="sourceCode python" tabindex="0"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>thresholds <span class="op">=</span> [<span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>]         <span class="co"># List of two thresholds to compare</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co"># Train Random Forest with probability estimates</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, max_depth<span class="op">=</span><span class="dv">6</span>, min_samples_split<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>model.fit(X_train, y_train)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co"># Predict probabilities</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X_test)[:, <span class="dv">1</span>]  <span class="co"># Probability of class 1</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co"># Plot side-by-side confusion matrices</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="cf">for</span> i, thresh <span class="kw">in</span> <span class="bu">enumerate</span>(thresholds):</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>    y_pred <span class="op">=</span> (y_proba <span class="op">&amp;</span>gt<span class="op">;=</span> thresh).astype(<span class="bu">int</span>)</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax<span class="op">=</span>axs[i])</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>    axs[i].set_title(<span class="ss">f"Threshold = </span><span class="sc">{</span>thresh<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>plt.show()</span></code></pre>
</div>
<figure><img src="10_random_forest_optimization/output_10_0.png" alt="png" class="figure mx-auto d-block"><div class="figcaption">png</div>
</figure><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 -->
</div>
</div>
</div></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/README.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries/workbench-template-md/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries/workbench-template-md/" class="external-link">Source</a></p>
				<p><a href="https://github.com/carpentries/workbench-template-md/blob/main/CITATION.cff" class="external-link">Cite</a> | <a href="mailto:training@qcif.edu.au">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.12" class="external-link">sandpaper (0.16.12)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.6" class="external-link">varnish (1.0.6)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries.github.io/workbench-template-md/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "machine learning, classification, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://carpentries.github.io/workbench-template-md/aio.html",
  "identifier": "https://carpentries.github.io/workbench-template-md/aio.html",
  "dateCreated": "2025-06-01",
  "dateModified": "2025-08-05",
  "datePublished": "2025-08-05"
}

  </script><script>
		feather.replace();
	</script>
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

